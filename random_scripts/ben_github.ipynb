{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return repo information for Neurodata using the [GitHub API](https://developer.github.com/v3/)\n",
    "\n",
    "- Personal access token can be generated here: https://github.com/settings/tokens\n",
    "  - Save token as text file in the same directory with name \"TOKEN\"\n",
    "- Scrape the contents of the API for the repo data:\n",
    "  - example response: https://developer.github.com/v3/repos/#response\n",
    "  - information about getting the repo list for an organization: https://developer.github.com/v3/repos/#list-organization-repositories\n",
    "  - information about getting the commits: https://developer.github.com/v3/repos/commits/\n",
    "- Note that responses are capped to 100 per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open('TOKEN','r') as myfile:\n",
    "    TOKEN=myfile.read().replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "with open('repo_data.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    objects = ['name','private','has_pages','description','pushed_at','last_commit_author',\n",
    "               'last_commit_date','last_commit_email','language','forks','open_issues',\n",
    "               'watchers']\n",
    "\n",
    "    writer.writerow(objects)\n",
    "\n",
    "    idx=1\n",
    "    resp=[]\n",
    "    while (len(resp)==100 or idx == 1):\n",
    "        u = urlopen('https://api.github.com/orgs/neurodata/repos?page=' + str(idx) + \n",
    "                    '&per_page=100&access_token=' + TOKEN +'&sort=full_name')\n",
    "        resp = json.loads(u.read().decode('utf-8'))\n",
    "        #pprint(resp)\n",
    "        #resp[1][\"name\"]\n",
    "\n",
    "        for repo in resp:\n",
    "            row=[]\n",
    "            for obj in objects:\n",
    "                if obj is 'last_commit_author':\n",
    "                    try:\n",
    "                        gu = urlopen('https://api.github.com/repos/neurodata/' + repo['name'] + \n",
    "                                     '/commits?access_token=' + TOKEN)\n",
    "                        git_commits = json.loads(gu.read().decode('utf-8'))\n",
    "\n",
    "                        #print(git_commits[0]['commit']['author']['name'])\n",
    "                        #print(git_commits[0]['commit']['author']['date'])\n",
    "                        row.append(git_commits[0]['commit']['author']['name'])\n",
    "                        row.append(git_commits[0]['commit']['author']['date'])\n",
    "                        row.append(git_commits[0]['commit']['author']['email'])\n",
    "                    except urllib.error.HTTPError as err:\n",
    "                        row.append(err.code)\n",
    "                        row.append('')\n",
    "                        row.append('')\n",
    "                elif obj is not 'last_commit_date' and obj is not 'last_commit_email':\n",
    "                    row.append(repo[obj])\n",
    "            #print(repo[\"name\"])\n",
    "            writer.writerow(row)\n",
    "        print(len(resp))\n",
    "        idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}